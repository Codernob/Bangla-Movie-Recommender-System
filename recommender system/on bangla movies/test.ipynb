{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspired by https://github.com/PacktPublishing/Python-Machine-Learning-By-Example-Third-Edition/blob/master/chapter2/movie_recommendation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import binascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bangla movie user rating dataset.csv')\n",
    "df.drop(4980)\n",
    "s = set()\n",
    "count = 1\n",
    "for ind in df.index:\n",
    "    serial = count\n",
    "    i = str(df['User_name'][ind])\n",
    "    if i in s:\n",
    "        continue\n",
    "    df.loc[ind,'U_ID'] = serial\n",
    "    for ind2 in range(ind+1,8):\n",
    "        j=str(df['User_name'][ind2])\n",
    "        if i==j:\n",
    "            df.at[ind2,'U_ID'] = serial\n",
    "    s.add(i)\n",
    "    count += 1\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to load rating data from file and also return the number of ratings for each movie and movie_id index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rating_data(n_users, n_movies):\n",
    "    \"\"\"\n",
    "    Load rating data from file and also return the number of ratings for each movie and movie_id index mapping\n",
    "    @param data_path: path of the rating data file\n",
    "    @param n_users: number of users\n",
    "    @param n_movies: number of movies that have ratings\n",
    "    @return: rating data in the numpy array of [user, movie]; movie_n_rating, {movie_id: number of ratings};\n",
    "             movie_id_mapping, {movie_id: column index in rating data}\n",
    "    \"\"\"\n",
    "    data = np.zeros([n_users, n_movies], dtype=np.float32)\n",
    "    movie_id_mapping = {}\n",
    "    movie_id_mapping = defaultdict(int)\n",
    "    df = pd.read_csv('bangla movie user rating dataset.csv')\n",
    "    df.insert(2,'U_ID',0) # creating a column U_ID with 0 in all rows\n",
    "\n",
    "    # now we will create user IDs in U_ID column\n",
    "    count = 1\n",
    "    s = set()\n",
    "    for ind in df.index:\n",
    "        serial = count\n",
    "        i = str(df['User_name'][ind])\n",
    "        if i in s:\n",
    "            continue\n",
    "        df.loc[ind,'U_ID'] = serial\n",
    "        for ind2 in range(ind+1,4987):\n",
    "            j=str(df['User_name'][ind2])\n",
    "            if i==j:\n",
    "                df.at[ind2,'U_ID'] = serial\n",
    "        s.add(i)\n",
    "        count += 1\n",
    "\n",
    "    # saving data from pandas dataframe `df` to numpy array `data`,dictionary `movie_id_mapping`, defaultdict `movie_id_mapping`\n",
    "    for ind in df.index:\n",
    "        user_id = df['U_ID'][ind]\n",
    "        user_id = int(user_id) - 1\n",
    "        movie_id = str(df['Movie_ID'][ind])\n",
    "        movie_id = int(movie_id[2:])\n",
    "        rating = int(df['Review Rating'][ind])\n",
    "        if movie_id not in movie_id_mapping:\n",
    "            movie_id_mapping[movie_id] = len(movie_id_mapping)\n",
    "        data[user_id, movie_id_mapping[movie_id]] = rating\n",
    "        if rating > 0:\n",
    "            movie_n_rating[movie_id] += 1\n",
    "    return data, movie_n_rating, movie_id_mapping\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "displaying rating info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_distribution(data):\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    for value, count in zip(values, counts):\n",
    "        print(f'Number of rating {int(value)}: {count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data and displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               User_name  U_ID\n",
      "0            adnannizhum     1\n",
      "1       SoumikBanerjee25     2\n",
      "2           MandalBros-5     3\n",
      "3     shovonbhattachrjee     4\n",
      "4       anandolodh-96284     5\n",
      "...                  ...   ...\n",
      "4982       yash-mahendra  3483\n",
      "4983     Pierre_Christen  3484\n",
      "4984           miguelopp  3485\n",
      "4985            dgerroll  3486\n",
      "4986        a_la_bakwaas  3487\n",
      "\n",
      "[4987 rows x 2 columns]\n",
      "Number of rating 0: 2802071\n",
      "Number of rating 1: 1881\n",
      "Number of rating 2: 115\n",
      "Number of rating 3: 146\n",
      "Number of rating 4: 138\n",
      "Number of rating 5: 199\n",
      "Number of rating 6: 336\n",
      "Number of rating 7: 470\n",
      "Number of rating 8: 806\n",
      "Number of rating 9: 873\n"
     ]
    }
   ],
   "source": [
    "n_users = 3487\n",
    "n_movies = 805\n",
    "data, movie_n_rating, movie_id_mapping = load_rating_data(n_users, n_movies)\n",
    "\n",
    "display_distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most ratings are unknown, we take the movie with the most known ratings as our target movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID 10834986 has 70 ratings.\n"
     ]
    }
   ],
   "source": [
    "movie_id_most, n_rating_most = sorted(movie_n_rating.items(), key=lambda d: d[1], reverse=True)[0]\n",
    "print(f'Movie ID {movie_id_most} has {n_rating_most} ratings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie with ID 10834986 is the target movie, and ratings of the rest of the movies are signals. We construct the dataset accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (70, 804)\n",
      "Shape of Y: (70,)\n"
     ]
    }
   ],
   "source": [
    "X_raw = np.delete(data, movie_id_mapping[movie_id_most], axis=1)\n",
    "Y_raw = data[:, movie_id_mapping[movie_id_most]]\n",
    "\n",
    "#We discard samples without a rating in movie ID 2858:\n",
    "X = X_raw[Y_raw > 0]\n",
    "Y = Y_raw[Y_raw > 0]\n",
    "\n",
    "print('Shape of X:', X.shape)\n",
    "print('Shape of Y:', Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we take a look at the distribution of the target movie ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rating 1: 41\n",
      "Number of rating 3: 3\n",
      "Number of rating 4: 1\n",
      "Number of rating 6: 2\n",
      "Number of rating 7: 6\n",
      "Number of rating 8: 8\n",
      "Number of rating 9: 9\n"
     ]
    }
   ],
   "source": [
    "display_distribution(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider movies with ratings greater than 3 as being liked (being recommended):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 positive samples and 44 negative samples.\n"
     ]
    }
   ],
   "source": [
    "recommend = 3\n",
    "Y[Y <= recommend] = 0\n",
    "Y[Y > recommend] = 1\n",
    "\n",
    "n_pos = (Y == 1).sum()\n",
    "n_neg = (Y == 0).sum()\n",
    "print(f'{n_pos} positive samples and {n_neg} negative samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rule of thumb in solving classification problems, we need to always analyze the label distribution and see how balanced (or imbalanced) the dataset is.\n",
    "\n",
    "Next, to comprehensively evaluate our classifier's performance, we can randomly split the dataset into two sets, the training and testing sets, which simulate learning data and prediction data, respectively. Generally, the proportion of the original dataset to include in the testing split can be 20%, 25%, 33.3%, or 40%. We use the train_test_split function from scikit-learn to do the random splitting and to preserve the percentage of samples for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(Y_train), len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the training and testing sizes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 14\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train), len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another good thing about the train_test_split function is that the resulting training and testing sets will have the same class ratio.\n",
    "\n",
    "Next, we train a Naïve Bayes model on the training set. You may notice that the values of the input features are from 0 to 5, as opposed to 0 or 1 in our toy example. Hence, we use the MultinomialNB module (https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) from scikit-learn instead of the BernoulliNB module, as MultinomialNB can work with integer features. We import the module, initialize a model with a smoothing factor of 1.0 and prior learned from the training set, and train this model against the training set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the trained model to make predictions on the testing set. We get the predicted probabilities as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.25000000e-01 3.75000000e-01]\n",
      " [1.00000000e+00 1.44008814e-11]\n",
      " [7.00619741e-01 2.99380259e-01]\n",
      " [9.27397060e-01 7.26029399e-02]\n",
      " [6.25000000e-01 3.75000000e-01]\n",
      " [6.25000000e-01 3.75000000e-01]\n",
      " [5.43252988e-12 1.00000000e+00]\n",
      " [6.25000000e-01 3.75000000e-01]\n",
      " [6.25000000e-01 3.75000000e-01]\n",
      " [8.45379717e-01 1.54620283e-01]]\n"
     ]
    }
   ],
   "source": [
    "prediction_prob = clf.predict_proba(X_test)\n",
    "print(prediction_prob[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the predicted class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(X_test)\n",
    "print(prediction[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the model's performance with classification accuracy, which is the proportion of correct predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 71.4%\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.score(X_test, Y_test)\n",
    "print(f'The accuracy is: {accuracy*100:.1f}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "639fde48ec0128a88b630484619c8c1a2f485ef59b6c38ec287b184a16f1b08e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
